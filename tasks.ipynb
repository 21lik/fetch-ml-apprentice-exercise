{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using Pytorch for my deep learning module, as I have the most experience with it from coursework and a summer program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Sentence Transformer Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, I referenced the textbook Dive into Deep Learning Chapter 11 Section 7 <https://d2l.ai/chapter_attention-mechanisms-and-transformers/transformer.html>, as well as my coursework from COMP SCI 539: Introduction to Artificial Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to implement the transformer architecture, modeled by the figure below:\n",
    "\n",
    "<img src=transformer.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to implement this from scratch, we would need to implement encoder and decoder layers, which would require implementing multi-head attention, feed-forward networks, etc. Fortunately, Pytorch provides a default Tranformer module, which we can use. However, we will still need to provide masked source and target sequences.\n",
    "\n",
    "First, we want to be able to convert a sentence to a fixed-size list of tokens (we will use words for convenience). We can use padding tokens to attain the specified word count. Next, we will want to convert the tokens into a list of indeces, each of which will correspond to a certain word. These indeces will be input to an Embedding layer, which will provide the embedded sequences.\n",
    "\n",
    "To do this, we will need to create a dictionary of words, as well as some auxilliary functions and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN_WORD = \"SOS\" # start of sentence\n",
    "END_TOKEN_WORD = \"EOS\" # end of sentence\n",
    "PAD_TOKEN_WORD = \"PAD\" # padding\n",
    "UNKNOWN_TOKEN_WORD = \"UNK\" # unknnown word # TODO: remove if unused\n",
    "\n",
    "START_TOKEN_IDX = 0 # start of sentence\n",
    "END_TOKEN_IDX = 1 # end of sentence\n",
    "PAD_TOKEN_IDX = 2 # padding\n",
    "UNKNOWN_TOKEN_IDX = 3 # unknnown word # TODO: remove if unused\n",
    "\n",
    "class WordDictionary:\n",
    "    def __init__(self):\n",
    "        self.word_to_index = {\n",
    "            START_TOKEN_WORD: START_TOKEN_IDX,\n",
    "            END_TOKEN_WORD: END_TOKEN_IDX,\n",
    "            PAD_TOKEN_WORD: PAD_TOKEN_IDX,\n",
    "            UNKNOWN_TOKEN_WORD: UNKNOWN_TOKEN_IDX,\n",
    "        }\n",
    "        self.index_to_word = {\n",
    "            START_TOKEN_IDX: START_TOKEN_WORD,\n",
    "            END_TOKEN_IDX: END_TOKEN_WORD,\n",
    "            PAD_TOKEN_IDX: PAD_TOKEN_WORD,\n",
    "            UNKNOWN_TOKEN_IDX: UNKNOWN_TOKEN_WORD,\n",
    "        }\n",
    "        self.word_to_count = {\n",
    "            START_TOKEN_WORD: 0,\n",
    "            END_TOKEN_WORD: 0,\n",
    "            PAD_TOKEN_WORD: 0,\n",
    "            UNKNOWN_TOKEN_WORD: 0,\n",
    "        }\n",
    "        self.n_words = 4\n",
    "\n",
    "    def add_word_list(self, sentence: list[str]):\n",
    "        for word in sentence:\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word: str):\n",
    "        if word in self.word_to_index:\n",
    "            self.word_to_count[word] += 1\n",
    "        else:\n",
    "            self.word_to_index[word] = self.n_words\n",
    "            self.word_to_count[word] = 1\n",
    "            self.index_to_word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "\n",
    "def tokenize_and_pad(sentence: str, token_count: int):\n",
    "    \"\"\"Tokenize the sentence to a list of fixed length.\"\"\"\n",
    "    word_list = sentence.split()\n",
    "    word_list.insert(0, START_TOKEN_WORD)\n",
    "    if (len(word_list) < token_count):\n",
    "        word_list.append(END_TOKEN_WORD)\n",
    "        word_list.extend([PAD_TOKEN_WORD] * (token_count - len(word_list)))\n",
    "    return word_list[:token_count]\n",
    "\n",
    "def word_list_to_indeces(word_list: list[str], word_dict: WordDictionary):\n",
    "    word_dict.add_word_list(word_list)\n",
    "    output = []\n",
    "    for word in word_list:\n",
    "        output.append(word_dict.word_to_index[word])\n",
    "    return output\n",
    "\n",
    "def indeces_to_word_list(indeces: list[int], word_dict: WordDictionary):\n",
    "    output = []\n",
    "    for idx in indeces:\n",
    "        output.append(word_dict.index_to_word[idx])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Multi-Task Learning Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Training Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Training Loop Implementation (BONUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2024_wqcc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
